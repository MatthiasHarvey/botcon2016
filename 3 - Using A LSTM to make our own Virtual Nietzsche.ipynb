{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's train a LSTM to mimick the writings of Nietzsche\n",
    "\n",
    "We're going to use [Keras](https://keras.io)  to generate Nietzsche like text. At least 20 epochs are required before the generated text starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n",
      "total chars: 59\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Read the entire file containing nietzsche's works\n",
    "path = './data/nietzsche.txt'\n",
    "text = open(path).read().lower()\n",
    "\n",
    "# Output the length of the corpus\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "# Create a sorted list of the characters\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates the overlapping windows with target characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200287\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary where given a character, you can look up the index and vice versa\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Step through the text via 3 characters at a time, taking a sequence of 40 bytes at a time. \n",
    "# There will be lots ofo overlap\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen]) # range from current index i for max length characters \n",
    "    next_chars.append(text[i + maxlen]) # the next character after that \n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates the 1 hot vectors for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Finished created vectors\n",
      "Size of patterns: 40\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Finished created vectors')\n",
    "print('Size of patterns:', len(X[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Compiling model complete...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "print(\"Compiling model complete...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to sample an index from a probability array\n",
    " The purpose of this function is to add some randomness so that the most likely character is not always chosen, and sometiems the 2nd or 3rd most likely cahracter is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now the actual training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity:  0.5\n",
      "Training...\n",
      "Epoch 1/20\n",
      "200287/200287 [==============================] - 184s - loss: 2.5244   \n",
      "Epoch 2/20\n",
      "200287/200287 [==============================] - 166s - loss: 2.1622   \n",
      "Epoch 3/20\n",
      "200287/200287 [==============================] - 166s - loss: 2.0296   \n",
      "Epoch 4/20\n",
      "200287/200287 [==============================] - 166s - loss: 1.9409   \n",
      "Epoch 5/20\n",
      "200287/200287 [==============================] - 166s - loss: 1.8724   \n",
      "Epoch 6/20\n",
      "200287/200287 [==============================] - 166s - loss: 1.8168   \n",
      "Epoch 7/20\n",
      "200287/200287 [==============================] - 166s - loss: 1.7713   \n",
      "Epoch 8/20\n",
      "200287/200287 [==============================] - 167s - loss: 1.7316   \n",
      "Epoch 9/20\n",
      "200287/200287 [==============================] - 167s - loss: 1.6963   \n",
      "Epoch 10/20\n",
      "200287/200287 [==============================] - 167s - loss: 1.6655   \n",
      "Epoch 11/20\n",
      "200287/200287 [==============================] - 167s - loss: 1.6383   \n",
      "Epoch 12/20\n",
      "200287/200287 [==============================] - 175s - loss: 1.6141   \n",
      "Epoch 13/20\n",
      "200287/200287 [==============================] - 168s - loss: 1.5939   \n",
      "Epoch 14/20\n",
      "200287/200287 [==============================] - 167s - loss: 1.5748   \n",
      "Epoch 15/20\n",
      "200287/200287 [==============================] - 168s - loss: 1.5569   \n",
      "Epoch 16/20\n",
      "200287/200287 [==============================] - 168s - loss: 1.5410   \n",
      "Epoch 17/20\n",
      "200287/200287 [==============================] - 168s - loss: 1.5272   \n",
      "Epoch 18/20\n",
      "200287/200287 [==============================] - 168s - loss: 1.5139   \n",
      "Epoch 19/20\n",
      "200287/200287 [==============================] - 168s - loss: 1.5010   \n",
      "Epoch 20/20\n",
      "200287/200287 [==============================] - 167s - loss: 1.4902   \n",
      "Generating with random seed: \"even more terrifying than other peoples \"\n",
      "even more terrifying than other peoples as the act of the aristically courable strengs of\n",
      "the strength the consequently present accourt and soul end and merial is not be not even the art a states and soul estauthous in the schoped of the most dissintured the found and the could be fact, of the happent how the strength and love of man is not be does for all the respect of the seems\n",
      "extained are such difficult of the sension us for him la"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4f8007311e90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Save the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nietzsche.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "diversity = 0.5\n",
    "print('Diversity: ', diversity)\n",
    "\n",
    "# The training\n",
    "print('Training...')\n",
    "history = model.fit(X, y, batch_size=128, nb_epoch=20)\n",
    "\n",
    "# Save the model\n",
    "model.save_weights('nietzsche.weights')\n",
    "json = model.to_json()\n",
    "f = open('nietzsche.json','w')\n",
    "f.write(json) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.load_weights('nietzsche.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.77245560e-05   9.27041256e-05   7.33234060e-07   4.18211948e-06\n",
      "   1.05271240e-04   3.59504284e-08   2.01290334e-07   3.80812162e-06\n",
      "   1.42704766e-06   1.96695760e-06   1.09209374e-07   3.10382461e-06\n",
      "   4.49063776e-07   2.25470080e-06   2.67015253e-06   1.75648040e-06\n",
      "   1.06952356e-07   3.99579960e-08   1.30287196e-06   6.63608333e-08\n",
      "   2.26742031e-07   2.24635201e-07   1.10115372e-09   2.13744428e-07\n",
      "   4.29951001e-07   2.12691859e-07   4.26919016e-08   1.63242130e-05\n",
      "   1.55780872e-03   1.91174258e-04   1.33617796e-04   2.30841706e-05\n",
      "   9.20703173e-01   4.84245975e-04   4.31293120e-05   1.13168990e-05\n",
      "   6.95453991e-06   7.76934394e-06   2.17955303e-03   3.47333873e-04\n",
      "   4.44710515e-02   6.89590699e-04   9.03360546e-04   2.25398549e-06\n",
      "   1.22935968e-02   5.78581297e-04   3.76695441e-03   4.58054664e-03\n",
      "   4.46888758e-03   2.20877700e-03   6.59294019e-05   3.15023794e-06\n",
      "   4.88524137e-08   3.31453476e-11   1.98800629e-11   7.59474688e-08\n",
      "   3.16799781e-11   2.32910392e-12   4.66942936e-07]\n",
      "1.00000002251\n"
     ]
    }
   ],
   "source": [
    "# Check out what our model predicts\n",
    "sentence = 'those who will not inherit the kingdom o'\n",
    "x = np.zeros((1, maxlen, len(chars)))\n",
    "for t, char in enumerate(sentence):\n",
    "    x[0, t, char_indices[char]] = 1.\n",
    "    \n",
    "print(model.predict(x, verbose=0)[0])\n",
    "print(sum(model.predict(x, verbose=0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those who will not inherit the kingdom of the prousing profound to whose things of the strengthing itself, which has his own and as a distinctions intellect, as the secting the been the stand is even his men of the sense is not only the sense. the religions and god and not of human interest and sufferen and about that is the spirit and its above the man in the spees as the ape forth to the extent is the seld means of religion, the \"prom\n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "original = sentence\n",
    "# Predict the next 400 characters based on the seed\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "print(original + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
